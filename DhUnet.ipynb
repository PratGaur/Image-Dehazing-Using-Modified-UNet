{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport math as m\nimport numpy as np\nimport torch as t\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom skimage.metrics import structural_similarity as ssim, \nfrom skimage.metrics import peak_signal_noise_ratio as psnr\n\nimport numpy as np\nfrom PIL import Image\nimport glob\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:04:29.271684Z","iopub.execute_input":"2023-03-29T22:04:29.272196Z","iopub.status.idle":"2023-03-29T22:04:31.100926Z","shell.execute_reply.started":"2023-03-29T22:04:29.272112Z","shell.execute_reply":"2023-03-29T22:04:31.099882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \nclass HazeDataset(Dataset):\n    def __init__(self, gt_images_path, hazy_images_path, transform=None):\n         \n        gt_image_paths = list(glob.glob(gt_images_path + '*.jpg'))\n        hazy_image_paths = list(glob.glob(hazy_images_path + '*.jpg'))\n\n        gt_images = []\n        hazy_images = []\n\n        for gt_image in gt_image_paths:\n            img_name = gt_image.split('/')[-1].split('.')[0]\n            for hazy_image in hazy_image_paths:\n                if hazy_image.find(img_name) != -1:\n                    gt_images.append(gt_image)\n                    hazy_images.append(hazy_image)\n\n#         total_images = len(gt_images)\n\n#         temp = list(zip(gt_images, hazy_images))\n#         np.random.shuffle(temp)\n#         gt_images, hazy_images = zip(*temp)\n\n#         if self.train:\n#             self.gt_image_paths = gt_images[: int(total_images * 0.9)]\n#             self.hazy_image_paths = hazy_images[: int(total_images * 0.9)]\n#         else:\n#             self.gt_image_paths = gt_images[int(total_images * 0.9) : ]\n#             self.hazy_image_paths = hazy_images[int(total_images * 0.9) : ]\n\n    def __getitem__(self, index):\n        gt_image = Image.open(self.gt_image_paths[index])\n        gt_image = np.array(gt_image, dtype=np.float32)\n        hazy_image = Image.open(self.hazy_image_paths[index])\n        hazy_image = np.array(hazy_image, dtype=np.float32)\n\n        gt_image /= 255\n        hazy_image /= 255\n\n        if transform:\n            gt_image  = self.transforms(gt_image)\n            hazy_image = self.transforms(hazy_image)\n            \n        return hazy_image, gt_image\n         \n    def __len__(self):\n        return len(self.gt_image_paths)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_crop(gt_image, hazy_image, target_shape = (224, 224)):\n    \n    x = np.random.randint(0, gt_image.shape[1] - target_shape[0])\n    y = np.random.randint(0, gt_image.shape[0] - target_shape[1])\n    \n    gt_image = gt_image[y : y + target_shape[0], x : x + target_shape[1]]\n    hazy_image = hazy_image[y : y + target_shape[0], x : x + target_shape[1]]\n    \n    return hazy_image, gt_image\n\n\n# load image \ndef load_image(hazy_image_path, gt_image_path):\n    \n    gt_image = Image.open(gt_image_path)\n    gt_image = np.array(gt_image, dtype=np.float32)\n    hazy_image = Image.open(hazy_image_path)\n    hazy_image = np.array(hazy_image, dtype=np.float32)\n    \n    # Random Crop the image as suggested in paper\n    hazy_image, gt_image = random_crop(gt_image, hazy_image)\n    gt_image /= 255\n    hazy_image /= 255\n    \n    gt_img_tensor = t.from_numpy(gt_image)\n    hazy_img_tensor = t.from_numpy(hazy_image)\n    \n    return hazy_img_tensor.permute(2, 0, 1), gt_img_tensor.permute(2, 0, 1)\n\n\n# Split dataset into train and validation splits\ndef get_data_splits(gt_images_path, hazy_images_path):\n    \n    gt_image_paths = list(glob.glob(gt_images_path + '*.jpg'))\n    hazy_image_paths = list(glob.glob(hazy_images_path + \"*.jpg\"))\n    \n    gt_images = []\n    hazy_images = []\n    \n    for gt_image in gt_image_paths:\n        img_name = gt_image.split('/')[-1].split('.')[0]\n        for hazy_image in hazy_image_paths:\n            if hazy_image.find(img_name) != -1:\n                gt_images.append(gt_image)\n                hazy_images.append(hazy_image)\n        \n    \n    total_images = len(gt_images)\n    \n    temp = list(zip(gt_images, hazy_images)) \n    np.random.shuffle(temp) \n    gt_images, hazy_images = zip(*temp)\n        \n    gt_images = list(gt_images)\n    hazy_images = list(hazy_images)\n    \n    \n    train_gt = gt_images[: int(total_images * 0.9)]\n    train_hazy = hazy_images[: int(total_images * 0.9)]\n    val_gt = gt_images[int(total_images * 0.9) : ]\n    val_hazy = hazy_images[int(total_images * 0.9) : ]\n    \n    \n    return {\n        'train_gt': train_gt,\n        'train_hazy': train_hazy,\n        'val_gt': val_gt,\n        'val_hazy': val_hazy\n    }\n\n\n# Custom Dataset with Hazy anf Ground Truth Images\nclass CustomDataset(Dataset):\n    def __init__(self, hazy_image_paths, gt_image_paths):\n        self.gt_image_paths = gt_image_paths\n        self.hazy_image_paths = hazy_image_paths\n        \n    def __getitem__(self, index):\n        return load_image(self.hazy_image_paths[index], self.gt_image_paths[index])\n\n    \n    def __len__(self):\n        return len(self.gt_image_paths)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:04:31.108341Z","iopub.execute_input":"2023-03-29T22:04:31.111146Z","iopub.status.idle":"2023-03-29T22:04:31.136300Z","shell.execute_reply.started":"2023-03-29T22:04:31.111105Z","shell.execute_reply":"2023-03-29T22:04:31.134340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv2(in_c, out_c):\n    conv = nn.Sequential(nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_c),\n            nn.ReLU(inplace=True),\n    )\n    return conv\n\ndef crop_img(tensor, target_tensor):\n\n    target_size = target_tensor.size()[2]\n    delta = target_size\n    # \n    return tensor[:, :,  :delta, :delta]\n\n\nclass DUnet(nn.Module):\n    def __init__(self):\n        super(DUnet, self).__init__()\n\n        self.maxP_2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        self.conv1 = conv2(3, 64)\n        self.conv2 = conv2(64, 64)\n        self.conv3 = conv2(64, 128)\n        self.conv4 = conv2(128, 128)\n        self.conv5 = conv2(128, 256)\n        self.conv6 = conv2(256, 256)\n        self.conv7 = conv2(256, 512)\n        self.conv8 = conv2(512, 512)\n        self.conv9 = conv2(512, 1024)\n\n        self.up_trans1 = nn.ConvTranspose2d(\n            in_channels = 1024,\n            out_channels = 512,\n            kernel_size = 4,\n            stride = 2, padding=1\n        )\n        self.up_conv1 = conv2(1024,512)\n\n        self.up_trans2 = nn.ConvTranspose2d(\n            in_channels = 512,\n            out_channels = 256,\n            kernel_size = 4,\n            stride = 2, padding=1\n        )\n        self.up_conv2 = conv2(512, 256)\n\n        self.up_trans3 = nn.ConvTranspose2d(\n            in_channels = 256,\n            out_channels = 128,\n            kernel_size = 4,\n            stride = 2, padding=1\n        )\n        self.up_conv3 = conv2(256,128)\n\n        self.up_trans4 = nn.ConvTranspose2d(\n            in_channels = 128,\n            out_channels = 64,\n            kernel_size = 4,\n            stride = 2, padding=1\n        )\n        self.up_conv4 = conv2(128, 64)\n\n        self.out = nn.Conv2d(\n            in_channels=64, \n            out_channels=3, \n            kernel_size=1)\n\n    def forward(self, input):\n\n        ######### INCODING #########\n\n        x1 = self.conv1(input)\n        x2 = self.conv2(x1)  # x = y1\n        xm = self.maxP_2(x2) \n        x3 = self.conv3(xm)\n        y1 = crop_img(x1, xm)\n        x4 = self.conv4(t.cat([xm, y1], axis=1))\n\n        xm2 = self.maxP_2(x4)\n        x5 = self.conv5(xm2) #y3\n\n        y2 = crop_img(x3, xm2)\n        x6 = self.conv6(t.cat([xm2, y2], axis=1))\n        x7 = self.conv6(x6)\n\n        xm3 = self.maxP_2(x7)\n        y3 = crop_img(x5, xm3)\n         \n        x8 = self.conv8(t.cat([xm3, y3], axis=1))\n        x9 = self.conv9(x8)\n        xm4 = self.maxP_2(x9)\n\n        ######## DECODEING #########\n\n        x = self.up_trans1(xm4)\n        y = crop_img(x8,x)\n        x = self.up_conv1(t.cat([x,y],1))\n        \n        x = self.up_trans2(x)\n        y = crop_img(x7,x)\n        x = self.up_conv2(t.cat([x,y],axis=1)) \n\n        x = self.up_trans3(x)\n        y = crop_img(x4,x)\n        x = self.up_conv3(t.cat([x,y],axis=1))\n\n        x = self.up_trans4(x)\n        y = crop_img(x2,x)\n        x = self.up_conv4(t.cat([x,y],axis=1))\n        \n        out = self.out(x)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:04:31.142186Z","iopub.execute_input":"2023-03-29T22:04:31.145618Z","iopub.status.idle":"2023-03-29T22:04:31.176433Z","shell.execute_reply.started":"2023-03-29T22:04:31.145578Z","shell.execute_reply":"2023-03-29T22:04:31.174980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm \n\ndevice = t.device('cuda' if t.cuda.is_available() else 'cpu')\n\ngt_path = '/kaggle/input/dehaze/clear_images/'\nhazy_path = '/kaggle/input/dehaze/haze/'\n\nbatch_size = 32\nn_epochs = 10\nlr = 0.0001\n\ntransform = transforms.Compose([\n                            transforms.RandomCrop((224, 224)),\n                            transforms.ToTensor()\n                        ])\n\n#print(device)\n\ndata_splits = get_data_splits(gt_path, hazy_path)\ntrain_dataset = CustomDataset(data_splits['train_hazy'], data_splits['train_gt'])\nval_dataset = CustomDataset(data_splits['val_hazy'], data_splits['val_gt'])\n\n# Training and Validation Data Loaders\n\ntrain_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\nval_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n\n\ndef show_image(hazy_image, gt_image, predicted_image):\n    \n    title = ['Hazy Image', 'Ground Truth Image', 'Predicted']\n\n    plt.figure(figsize=(15, 15))\n    display_list = [\n                        hazy_image.cpu().permute(1, 2, 0).numpy(),\n                        gt_image.cpu().permute(1, 2, 0).numpy(),\n                        predicted_image.detach().cpu().permute(1, 2, 0).numpy()\n                   ]\n\n    for i in range(3):\n        plt.subplot(1, 3, i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n        \n    plt.show()\n\n\ndef init_weights(m):\n    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n        t.nn.init.normal_(m.weight, mean=0.0, std=0.008)\n        m.bias.data.fill_(0.01)\n        \nnet = DUnet().to(device)\nnet.apply(init_weights)\nopt = t.optim.Adam(net.parameters(), lr = lr)\ncriterion = nn.MSELoss()\n\n\n\nfor epoch in range(n_epochs):\n    total_train_loss = 0\n    total_val_loss = 0\n    ssim_score = 0.0     \n    psnr_score = 0.0\n    start_time = time.time()\n    \n    \n    print(f'Epoch {epoch + 1} started...')\n   \n    net.train()\n    for (hazy_images, gt_images) in tqdm(train_dataloader):\n        curr_batch_size = hazy_images.size()\n        hazy_images = hazy_images.to(device)\n        gt_images = gt_images.to(device)\n        \n        k = net(hazy_images)\n        outputs = k*hazy_images - k + 1.0\n\n        train_loss = criterion(outputs, gt_images)\n        opt.zero_grad()\n        train_loss.backward()\n        opt.step()\n        total_train_loss += train_loss.item() \n    \n    with torch.zero_grad()\n        for(hazy_images, gt_images) in val_dataloader:\n            with t.no_grad():\n                hazy_images = hazy_images.to(device)\n                gt_images = gt_images.to(device)\n                k = net(hazy_images)\n                outputs = k*hazy_images - k + 1.0\n                \n                if epoch%5:\n                    show_image(hazy_images[0], gt_images[0], outputs[0])\n\n                val_loss = criterion(outputs, gt_images)\n                total_val_loss += val_loss.item() \n                \n                for j in range(outputs.size()[0]):\n                    ssim_score += ssim(outputs[j, 0, :, :].detach().cpu().numpy(),\n                                       gt_images[j, :, :].detach().cpu().numpy(), data_range=1)\n                    psnr_score += psnr(outputs[j, 0, :, :].detach().cpu().numpy(),\n                                       gt_images[j, :, :].detach().cpu().numpy(), data_range=1)\n        \n        print(f'SSMI_score: {ssim_score / (len(val_dataloader) * outputs.size()[0])})\n        print(f'PSNR_score: {psnr / (len(val_dataloader) * outputs.size()[0])})\n        \n        print(f'Total train loss: {total_train_loss}')\n        print(f'Total validation loss: {total_val_loss}')\n    \n    end_time = time.time()\n    \n    print(f'Epoch {epoch + 1} ended, time taken: {end_time - start_time}s')\n        \n        \nt.save(net.state_dict(), 'state_dict_model.pt')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:21:15.500344Z","iopub.execute_input":"2023-03-29T22:21:15.500719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}